{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"alexnet_cifar10_keras_1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOvYzWT+d65TvO2mmXZ/Vpp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uc8x5q9zzBFZ","executionInfo":{"status":"ok","timestamp":1634624374167,"user_tz":-540,"elapsed":6452195,"user":{"displayName":"吉岡拓郎","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivDrWZ1YeCaV-Feco-eGXgW12UwU-9LbcBnxtXdw=s64","userId":"15756181896059802111"}},"outputId":"d25b7a04-cad6-4e12-9750-1088bc34432a"},"source":["import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n","from keras.initializers import TruncatedNormal, Constant\n","#追加train.py\n","from tensorflow.keras import utils as np_utils\n","from tensorflow.keras.optimizers import SGD \n","from keras.datasets import cifar10\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","\n","#alexnet_cifar10.py\n","def conv2d(filters, kernel_size, strides=(1, 1), padding='same', bias_init=1, **kwargs):\n","    trunc = TruncatedNormal(mean=0.0, stddev=0.01)\n","    cnst = Constant(value=bias_init)\n","    return Conv2D(\n","        filters, kernel_size, strides=strides, padding=padding,\n","        activation='relu', kernel_initializer=trunc, bias_initializer=cnst, **kwargs\n","    )   \n","\n","def dense(units, activation='tanh'):\n","    trunc = TruncatedNormal(mean=0.0, stddev=0.01)\n","    cnst = Constant(value=1)\n","    return Dense(\n","        units, activation=activation,\n","        kernel_initializer=trunc, bias_initializer=cnst,\n","    )   \n","\n","def AlexNet(image_size, channel, num_classes):\n","    model = Sequential()\n","\n","    #conv1\n","    model.add(conv2d(96, 3, bias_init=0, input_shape=(image_size, image_size, channel)))\n","    #pool1\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n","    model.add(BatchNormalization())\n","\n","    #conv2\n","    model.add(conv2d(256, 5)) \n","    #pool2\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n","    model.add(BatchNormalization())\n","\n","    #conv3\n","    model.add(conv2d(384, 3, bias_init=0))\n","    #conv4\n","    model.add(conv2d(384, 3)) \n","    #conv5\n","    model.add(conv2d(256, 3)) \n","    #pool5\n","    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n","    model.add(BatchNormalization())\n","\n","    #fc6\n","    model.add(Flatten())\n","    model.add(dense(4096))\n","    model.add(Dropout(0.5))\n","    #fc7\n","    model.add(dense(4096))\n","    model.add(Dropout(0.5))\n","\n","    #fc8\n","    model.add(dense(num_classes, activation='softmax'))\n","    \n","    return model\n","\n","#train.py\n","\n","batch_size = 128 \n","num_classes = 10\n","epochs = 100 \n","image_size = 32\n","channel = 3 \n","\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","y_train = np_utils.to_categorical(y_train, num_classes)\n","y_test = np_utils.to_categorical(y_test, num_classes)\n","\n","model = AlexNet(image_size, channel, num_classes)\n","model.compile(optimizer=SGD(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","model.summary()\n","\n","train_gen = ImageDataGenerator(rescale=1.0/255, horizontal_flip=True, \n","                width_shift_range=4.0/32.0, height_shift_range=4.0/32.0)\n","test_gen = ImageDataGenerator(rescale=1.0/255)\n","\n","model.fit_generator(train_gen.flow(x_train, y_train, batch_size, shuffle=True),\n","                        steps_per_epoch=x_train.shape[0]//batch_size,\n","                        validation_data=test_gen.flow(x_test, y_test, batch_size, shuffle=False),\n","                        validation_steps=x_test.shape[0]//batch_size,\n","                        max_queue_size=5, epochs=epochs)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 2s 0us/step\n","170508288/170498071 [==============================] - 2s 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 32, 32, 96)        2688      \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 16, 16, 96)        0         \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 16, 16, 96)        384       \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 16, 16, 256)       614656    \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 8, 8, 256)         0         \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 8, 8, 256)         1024      \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 8, 8, 384)         885120    \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 8, 8, 384)         1327488   \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 8, 8, 256)         884992    \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","flatten (Flatten)            (None, 4096)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 4096)              16781312  \n","_________________________________________________________________\n","dropout (Dropout)            (None, 4096)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 4096)              16781312  \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 4096)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                40970     \n","=================================================================\n","Total params: 37,320,970\n","Trainable params: 37,319,754\n","Non-trainable params: 1,216\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","390/390 [==============================] - 82s 127ms/step - loss: 1.9743 - accuracy: 0.2834 - val_loss: 2.1851 - val_accuracy: 0.2221\n","Epoch 2/100\n","390/390 [==============================] - 48s 124ms/step - loss: 1.4736 - accuracy: 0.4580 - val_loss: 1.2276 - val_accuracy: 0.5497\n","Epoch 3/100\n","390/390 [==============================] - 48s 123ms/step - loss: 1.2689 - accuracy: 0.5388 - val_loss: 1.3214 - val_accuracy: 0.5368\n","Epoch 4/100\n","390/390 [==============================] - 48s 123ms/step - loss: 1.1312 - accuracy: 0.5943 - val_loss: 1.4442 - val_accuracy: 0.5198\n","Epoch 5/100\n","390/390 [==============================] - 48s 123ms/step - loss: 1.0282 - accuracy: 0.6340 - val_loss: 1.5141 - val_accuracy: 0.5049\n","Epoch 6/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.9559 - accuracy: 0.6592 - val_loss: 1.1642 - val_accuracy: 0.6189\n","Epoch 7/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.8879 - accuracy: 0.6874 - val_loss: 0.8787 - val_accuracy: 0.6989\n","Epoch 8/100\n","390/390 [==============================] - 48s 124ms/step - loss: 0.8389 - accuracy: 0.7056 - val_loss: 0.9427 - val_accuracy: 0.6730\n","Epoch 9/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.7936 - accuracy: 0.7201 - val_loss: 0.8524 - val_accuracy: 0.7100\n","Epoch 10/100\n","390/390 [==============================] - 48s 124ms/step - loss: 0.7641 - accuracy: 0.7308 - val_loss: 1.1580 - val_accuracy: 0.6486\n","Epoch 11/100\n","390/390 [==============================] - 48s 124ms/step - loss: 0.7332 - accuracy: 0.7451 - val_loss: 0.7342 - val_accuracy: 0.7543\n","Epoch 12/100\n","390/390 [==============================] - 48s 124ms/step - loss: 0.7010 - accuracy: 0.7533 - val_loss: 0.7218 - val_accuracy: 0.7600\n","Epoch 13/100\n","390/390 [==============================] - 48s 124ms/step - loss: 0.6749 - accuracy: 0.7630 - val_loss: 0.8451 - val_accuracy: 0.7165\n","Epoch 14/100\n","390/390 [==============================] - 48s 124ms/step - loss: 0.6481 - accuracy: 0.7729 - val_loss: 0.8649 - val_accuracy: 0.7147\n","Epoch 15/100\n","390/390 [==============================] - 48s 124ms/step - loss: 0.6256 - accuracy: 0.7780 - val_loss: 0.7392 - val_accuracy: 0.7589\n","Epoch 16/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.6033 - accuracy: 0.7883 - val_loss: 0.6964 - val_accuracy: 0.7648\n","Epoch 17/100\n","390/390 [==============================] - 48s 124ms/step - loss: 0.5874 - accuracy: 0.7935 - val_loss: 0.6642 - val_accuracy: 0.7803\n","Epoch 18/100\n","390/390 [==============================] - 48s 124ms/step - loss: 0.5735 - accuracy: 0.7980 - val_loss: 0.6954 - val_accuracy: 0.7694\n","Epoch 19/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.5558 - accuracy: 0.8060 - val_loss: 0.6310 - val_accuracy: 0.7881\n","Epoch 20/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.5355 - accuracy: 0.8154 - val_loss: 0.7326 - val_accuracy: 0.7682\n","Epoch 21/100\n","390/390 [==============================] - 48s 122ms/step - loss: 0.5229 - accuracy: 0.8171 - val_loss: 0.6790 - val_accuracy: 0.7782\n","Epoch 22/100\n","390/390 [==============================] - 48s 122ms/step - loss: 0.5062 - accuracy: 0.8233 - val_loss: 0.5945 - val_accuracy: 0.8023\n","Epoch 23/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.4943 - accuracy: 0.8268 - val_loss: 0.5687 - val_accuracy: 0.8123\n","Epoch 24/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.4841 - accuracy: 0.8305 - val_loss: 0.7020 - val_accuracy: 0.7757\n","Epoch 25/100\n","390/390 [==============================] - 48s 122ms/step - loss: 0.4674 - accuracy: 0.8365 - val_loss: 0.7541 - val_accuracy: 0.7623\n","Epoch 26/100\n","390/390 [==============================] - 48s 122ms/step - loss: 0.4562 - accuracy: 0.8411 - val_loss: 0.6191 - val_accuracy: 0.7994\n","Epoch 27/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.4450 - accuracy: 0.8425 - val_loss: 0.7951 - val_accuracy: 0.7593\n","Epoch 28/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.4303 - accuracy: 0.8491 - val_loss: 0.7104 - val_accuracy: 0.7801\n","Epoch 29/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.4231 - accuracy: 0.8495 - val_loss: 0.5954 - val_accuracy: 0.8097\n","Epoch 30/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.4109 - accuracy: 0.8557 - val_loss: 0.7409 - val_accuracy: 0.7782\n","Epoch 31/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.4023 - accuracy: 0.8582 - val_loss: 0.5618 - val_accuracy: 0.8140\n","Epoch 32/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.3951 - accuracy: 0.8604 - val_loss: 0.6025 - val_accuracy: 0.8026\n","Epoch 33/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.3868 - accuracy: 0.8631 - val_loss: 0.6384 - val_accuracy: 0.8080\n","Epoch 34/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.3755 - accuracy: 0.8686 - val_loss: 0.6869 - val_accuracy: 0.7981\n","Epoch 35/100\n","390/390 [==============================] - 48s 124ms/step - loss: 0.3662 - accuracy: 0.8727 - val_loss: 0.5806 - val_accuracy: 0.8124\n","Epoch 36/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.3566 - accuracy: 0.8740 - val_loss: 0.6374 - val_accuracy: 0.8050\n","Epoch 37/100\n","390/390 [==============================] - 48s 124ms/step - loss: 0.3473 - accuracy: 0.8780 - val_loss: 0.6853 - val_accuracy: 0.8012\n","Epoch 38/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.3418 - accuracy: 0.8794 - val_loss: 0.6026 - val_accuracy: 0.8181\n","Epoch 39/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.3310 - accuracy: 0.8838 - val_loss: 1.0720 - val_accuracy: 0.7274\n","Epoch 40/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.3278 - accuracy: 0.8839 - val_loss: 0.5332 - val_accuracy: 0.8362\n","Epoch 41/100\n","390/390 [==============================] - 48s 122ms/step - loss: 0.3152 - accuracy: 0.8881 - val_loss: 0.7243 - val_accuracy: 0.7911\n","Epoch 42/100\n","390/390 [==============================] - 48s 122ms/step - loss: 0.3090 - accuracy: 0.8930 - val_loss: 0.5109 - val_accuracy: 0.8363\n","Epoch 43/100\n","390/390 [==============================] - 48s 122ms/step - loss: 0.3005 - accuracy: 0.8934 - val_loss: 0.5559 - val_accuracy: 0.8308\n","Epoch 44/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.2945 - accuracy: 0.8958 - val_loss: 0.7023 - val_accuracy: 0.7997\n","Epoch 45/100\n","390/390 [==============================] - 48s 122ms/step - loss: 0.2893 - accuracy: 0.8978 - val_loss: 0.5238 - val_accuracy: 0.8404\n","Epoch 46/100\n","390/390 [==============================] - 48s 122ms/step - loss: 0.2855 - accuracy: 0.8990 - val_loss: 0.6498 - val_accuracy: 0.8119\n","Epoch 47/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.2752 - accuracy: 0.9026 - val_loss: 0.6325 - val_accuracy: 0.8221\n","Epoch 48/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.2720 - accuracy: 0.9043 - val_loss: 0.5745 - val_accuracy: 0.8304\n","Epoch 49/100\n","390/390 [==============================] - 48s 124ms/step - loss: 0.2593 - accuracy: 0.9084 - val_loss: 0.6517 - val_accuracy: 0.8061\n","Epoch 50/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.2604 - accuracy: 0.9092 - val_loss: 0.6800 - val_accuracy: 0.8065\n","Epoch 51/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.2536 - accuracy: 0.9108 - val_loss: 0.6046 - val_accuracy: 0.8237\n","Epoch 52/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.2448 - accuracy: 0.9138 - val_loss: 0.8354 - val_accuracy: 0.7897\n","Epoch 53/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.2401 - accuracy: 0.9165 - val_loss: 0.5407 - val_accuracy: 0.8453\n","Epoch 54/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.2326 - accuracy: 0.9189 - val_loss: 0.6489 - val_accuracy: 0.8239\n","Epoch 55/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.2315 - accuracy: 0.9170 - val_loss: 0.7840 - val_accuracy: 0.7968\n","Epoch 56/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.2253 - accuracy: 0.9194 - val_loss: 0.6481 - val_accuracy: 0.8207\n","Epoch 57/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.2178 - accuracy: 0.9220 - val_loss: 0.5558 - val_accuracy: 0.8426\n","Epoch 58/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.2133 - accuracy: 0.9244 - val_loss: 0.5340 - val_accuracy: 0.8487\n","Epoch 59/100\n","390/390 [==============================] - 48s 124ms/step - loss: 0.2049 - accuracy: 0.9269 - val_loss: 0.6219 - val_accuracy: 0.8317\n","Epoch 60/100\n","390/390 [==============================] - 49s 125ms/step - loss: 0.2038 - accuracy: 0.9265 - val_loss: 0.6086 - val_accuracy: 0.8372\n","Epoch 61/100\n","390/390 [==============================] - 49s 125ms/step - loss: 0.2020 - accuracy: 0.9280 - val_loss: 0.6421 - val_accuracy: 0.8226\n","Epoch 62/100\n","390/390 [==============================] - 49s 125ms/step - loss: 0.1955 - accuracy: 0.9300 - val_loss: 0.7178 - val_accuracy: 0.8216\n","Epoch 63/100\n","390/390 [==============================] - 49s 124ms/step - loss: 0.1939 - accuracy: 0.9305 - val_loss: 0.6486 - val_accuracy: 0.8284\n","Epoch 64/100\n","390/390 [==============================] - 49s 124ms/step - loss: 0.1873 - accuracy: 0.9327 - val_loss: 0.5776 - val_accuracy: 0.8419\n","Epoch 65/100\n","390/390 [==============================] - 48s 124ms/step - loss: 0.1822 - accuracy: 0.9343 - val_loss: 0.5959 - val_accuracy: 0.8331\n","Epoch 66/100\n","390/390 [==============================] - 49s 125ms/step - loss: 0.1791 - accuracy: 0.9357 - val_loss: 0.5635 - val_accuracy: 0.8445\n","Epoch 67/100\n","390/390 [==============================] - 48s 124ms/step - loss: 0.1761 - accuracy: 0.9372 - val_loss: 0.6377 - val_accuracy: 0.8356\n","Epoch 68/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.1754 - accuracy: 0.9381 - val_loss: 0.7091 - val_accuracy: 0.8300\n","Epoch 69/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.1686 - accuracy: 0.9411 - val_loss: 0.6448 - val_accuracy: 0.8315\n","Epoch 70/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.1648 - accuracy: 0.9412 - val_loss: 0.8402 - val_accuracy: 0.7972\n","Epoch 71/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.1626 - accuracy: 0.9421 - val_loss: 0.5877 - val_accuracy: 0.8484\n","Epoch 72/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.1583 - accuracy: 0.9438 - val_loss: 0.7390 - val_accuracy: 0.8114\n","Epoch 73/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.1525 - accuracy: 0.9456 - val_loss: 0.6380 - val_accuracy: 0.8333\n","Epoch 74/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.1491 - accuracy: 0.9466 - val_loss: 0.7114 - val_accuracy: 0.8330\n","Epoch 75/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.1467 - accuracy: 0.9477 - val_loss: 0.6482 - val_accuracy: 0.8379\n","Epoch 76/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.1418 - accuracy: 0.9489 - val_loss: 0.6220 - val_accuracy: 0.8411\n","Epoch 77/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.1404 - accuracy: 0.9498 - val_loss: 0.7756 - val_accuracy: 0.8178\n","Epoch 78/100\n","390/390 [==============================] - 48s 124ms/step - loss: 0.1419 - accuracy: 0.9493 - val_loss: 0.7324 - val_accuracy: 0.8288\n","Epoch 79/100\n","390/390 [==============================] - 48s 124ms/step - loss: 0.1291 - accuracy: 0.9534 - val_loss: 0.8467 - val_accuracy: 0.8124\n","Epoch 80/100\n","390/390 [==============================] - 48s 124ms/step - loss: 0.1355 - accuracy: 0.9512 - val_loss: 0.6129 - val_accuracy: 0.8501\n","Epoch 81/100\n","390/390 [==============================] - 48s 124ms/step - loss: 0.1295 - accuracy: 0.9534 - val_loss: 0.8182 - val_accuracy: 0.8191\n","Epoch 82/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.1234 - accuracy: 0.9565 - val_loss: 0.7034 - val_accuracy: 0.8337\n","Epoch 83/100\n","390/390 [==============================] - 48s 124ms/step - loss: 0.1266 - accuracy: 0.9545 - val_loss: 0.7165 - val_accuracy: 0.8309\n","Epoch 84/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.1236 - accuracy: 0.9555 - val_loss: 0.6983 - val_accuracy: 0.8357\n","Epoch 85/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.1196 - accuracy: 0.9575 - val_loss: 0.7772 - val_accuracy: 0.8225\n","Epoch 86/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.1222 - accuracy: 0.9562 - val_loss: 0.6364 - val_accuracy: 0.8507\n","Epoch 87/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.1184 - accuracy: 0.9579 - val_loss: 0.6345 - val_accuracy: 0.8449\n","Epoch 88/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.1121 - accuracy: 0.9597 - val_loss: 0.6670 - val_accuracy: 0.8488\n","Epoch 89/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.1143 - accuracy: 0.9595 - val_loss: 0.6485 - val_accuracy: 0.8476\n","Epoch 90/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.1104 - accuracy: 0.9608 - val_loss: 0.6180 - val_accuracy: 0.8569\n","Epoch 91/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.1079 - accuracy: 0.9619 - val_loss: 0.5816 - val_accuracy: 0.8631\n","Epoch 92/100\n","390/390 [==============================] - 48s 124ms/step - loss: 0.1071 - accuracy: 0.9616 - val_loss: 0.6512 - val_accuracy: 0.8481\n","Epoch 93/100\n","390/390 [==============================] - 48s 124ms/step - loss: 0.1025 - accuracy: 0.9626 - val_loss: 0.6880 - val_accuracy: 0.8410\n","Epoch 94/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.1048 - accuracy: 0.9628 - val_loss: 0.7848 - val_accuracy: 0.8354\n","Epoch 95/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.1022 - accuracy: 0.9625 - val_loss: 0.6936 - val_accuracy: 0.8491\n","Epoch 96/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.0972 - accuracy: 0.9643 - val_loss: 0.8207 - val_accuracy: 0.8335\n","Epoch 97/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.0973 - accuracy: 0.9656 - val_loss: 0.7396 - val_accuracy: 0.8358\n","Epoch 98/100\n","390/390 [==============================] - 48s 124ms/step - loss: 0.0973 - accuracy: 0.9652 - val_loss: 0.7663 - val_accuracy: 0.8294\n","Epoch 99/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.0950 - accuracy: 0.9666 - val_loss: 0.6113 - val_accuracy: 0.8666\n","Epoch 100/100\n","390/390 [==============================] - 48s 123ms/step - loss: 0.0915 - accuracy: 0.9675 - val_loss: 0.8584 - val_accuracy: 0.8282\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f4cd02c4dd0>"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"o3U0-iaTRqdD","executionInfo":{"status":"ok","timestamp":1634626133972,"user_tz":-540,"elapsed":687,"user":{"displayName":"吉岡拓郎","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivDrWZ1YeCaV-Feco-eGXgW12UwU-9LbcBnxtXdw=s64","userId":"15756181896059802111"}}},"source":["model.save('alexnet_cifar10.h5')"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UdNnBKhl4n-h","executionInfo":{"status":"ok","timestamp":1635223939986,"user_tz":-540,"elapsed":394,"user":{"displayName":"吉岡拓郎","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivDrWZ1YeCaV-Feco-eGXgW12UwU-9LbcBnxtXdw=s64","userId":"15756181896059802111"}},"outputId":"833e0d78-badc-4902-8f71-eed7296c5058"},"source":["from keras.models import load_model\n","\n","model = load_model('alexnet_cifar10.h5')\n","model.summary()  # As a reminder."],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 32, 32, 96)        2688      \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 16, 16, 96)        0         \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 16, 16, 96)        384       \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 16, 16, 256)       614656    \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 8, 8, 256)         0         \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 8, 8, 256)         1024      \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 8, 8, 384)         885120    \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 8, 8, 384)         1327488   \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 8, 8, 256)         884992    \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","flatten (Flatten)            (None, 4096)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 4096)              16781312  \n","_________________________________________________________________\n","dropout (Dropout)            (None, 4096)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 4096)              16781312  \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 4096)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                40970     \n","=================================================================\n","Total params: 37,320,970\n","Trainable params: 37,319,754\n","Non-trainable params: 1,216\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"d-_tadgmVedW","executionInfo":{"status":"ok","timestamp":1635223975997,"user_tz":-540,"elapsed":28407,"user":{"displayName":"吉岡拓郎","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivDrWZ1YeCaV-Feco-eGXgW12UwU-9LbcBnxtXdw=s64","userId":"15756181896059802111"}}},"source":["from keras.preprocessing import image\n","import numpy as np\n","#ターゲット(画像)へのローカルパス\n","img_path = \"/content/test_00003.png\"\n","\n","#画像を読み込む　:imgはサイズが224*224のPIL画像(Pythonで画像を処理するためのライブラリ)\n","img = image.load_img(img_path, target_size=(32,32))\n","\n","#xは形状が(224,224，3)のfloat32型のNumPy配列\n","x = image.img_to_array(img)\n","\n","#この配列がサイズが(1,224,224,3)のバッチに変換するために次元を追加\n","x = np.expand_dims(x, axis=0)\n","\n","#予測ベクトルを人が読める形にデコード\n","preds = model.predict(x)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"id":"bOLuVWbfeXAg","executionInfo":{"status":"ok","timestamp":1635224005349,"user_tz":-540,"elapsed":401,"user":{"displayName":"吉岡拓郎","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivDrWZ1YeCaV-Feco-eGXgW12UwU-9LbcBnxtXdw=s64","userId":"15756181896059802111"}},"outputId":"3312e6f4-25f1-45d2-acbc-b58154019dee"},"source":["import matplotlib.pyplot as plt\n","\n","plt.imshow(x[0])\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"pMnFkmjzghaV","executionInfo":{"status":"ok","timestamp":1635224019240,"user_tz":-540,"elapsed":381,"user":{"displayName":"吉岡拓郎","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivDrWZ1YeCaV-Feco-eGXgW12UwU-9LbcBnxtXdw=s64","userId":"15756181896059802111"}}},"source":["from keras import models\n","\n","# Extracts the outputs of the top 8 layers:\n","layer_outputs = [layer.output for layer in model.layers[:12]]\n","# Creates a model that will return these outputs, given the model input:\n","activation_model = models.Model(inputs=model.input, outputs=layer_outputs)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"aJPO7GjYgliS","executionInfo":{"status":"ok","timestamp":1635224021806,"user_tz":-540,"elapsed":2,"user":{"displayName":"吉岡拓郎","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivDrWZ1YeCaV-Feco-eGXgW12UwU-9LbcBnxtXdw=s64","userId":"15756181896059802111"}}},"source":["# This will return a list of 5 Numpy arrays:\n","# one array per layer activation\n","activations = activation_model.predict(x)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"HISDexZNg1fw"},"source":["x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RHog090jg4VI","executionInfo":{"status":"ok","timestamp":1635224042087,"user_tz":-540,"elapsed":385,"user":{"displayName":"吉岡拓郎","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivDrWZ1YeCaV-Feco-eGXgW12UwU-9LbcBnxtXdw=s64","userId":"15756181896059802111"}},"outputId":"d3d388b8-d665-4642-df91-58ca04ff54e0"},"source":["\n","import numpy as np\n","first_layer_activation = activations[11]\n","print(first_layer_activation.shape)\n","#preds = first_layer_activation.predict(x)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 4096)\n"]}]},{"cell_type":"code","metadata":{"id":"TLfowZ3bg-QV"},"source":["import matplotlib.pyplot as plt\n","\n","plt.matshow(first_layer_activation[0, :, :, 30], cmap='viridis')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_e4ad48jY5IH","executionInfo":{"status":"ok","timestamp":1635224081582,"user_tz":-540,"elapsed":359,"user":{"displayName":"吉岡拓郎","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivDrWZ1YeCaV-Feco-eGXgW12UwU-9LbcBnxtXdw=s64","userId":"15756181896059802111"}},"outputId":"24f7f035-0315-45d2-ced1-de6dc9efc78f"},"source":["preds.shape"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 10)"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZkMCN5BfY8gP","executionInfo":{"status":"ok","timestamp":1635224083595,"user_tz":-540,"elapsed":494,"user":{"displayName":"吉岡拓郎","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivDrWZ1YeCaV-Feco-eGXgW12UwU-9LbcBnxtXdw=s64","userId":"15756181896059802111"}},"outputId":"9450022f-b93d-45d5-b8e7-bc896333ec7d"},"source":["preds"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.5428006e-05, 7.7603209e-01, 5.3995440e-04, 1.5739312e-04,\n","        7.4232899e-05, 1.5846534e-04, 1.4179606e-04, 2.2286402e-01,\n","        9.9675213e-10, 1.6595284e-05]], dtype=float32)"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"hMX-Rar8frG8"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"BoHEQcOnU8wh","executionInfo":{"status":"ok","timestamp":1634626468958,"user_tz":-540,"elapsed":284,"user":{"displayName":"吉岡拓郎","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivDrWZ1YeCaV-Feco-eGXgW12UwU-9LbcBnxtXdw=s64","userId":"15756181896059802111"}},"outputId":"fe89f773-141c-441b-8017-eae59f6a1993"},"source":["\"\"\"\n","history = model.fit_generator(train_gen.flow(x_train, y_train, batch_size, shuffle=True),\n","                        steps_per_epoch=x_train.shape[0]//batch_size,\n","                        validation_data=test_gen.flow(x_test, y_test, batch_size, shuffle=False),\n","                        validation_steps=x_test.shape[0]//batch_size,\n","                        max_queue_size=5, epochs=epochs)\n","                        \"\"\""],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nhistory = model.fit_generator(train_gen.flow(x_train, y_train, batch_size, shuffle=True),\\n                        steps_per_epoch=x_train.shape[0]//batch_size,\\n                        validation_data=test_gen.flow(x_test, y_test, batch_size, shuffle=False),\\n                        validation_steps=x_test.shape[0]//batch_size,\\n                        max_queue_size=5, epochs=epochs)\\n                        '"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"6OTD5-F_N1BQ"},"source":[""],"execution_count":null,"outputs":[]}]}