{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cifar10_vector_csv.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1nS5eNDyatP-zhaWTKB59-Cyr9h2u_S0v","authorship_tag":"ABX9TyNRzfCRNXxYi2VtidUAimRD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"X6YF4fmqT1Yj"},"source":["# cifar10データセットの画像を使い，1万件の予測ベクトルを取得"]},{"cell_type":"markdown","metadata":{"id":"JhfNUrKNUVUI"},"source":["## 作成済みモデルのロード"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XNgoQ_5_T0Xy","executionInfo":{"status":"ok","timestamp":1637035669714,"user_tz":-540,"elapsed":8754,"user":{"displayName":"吉岡拓郎","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivDrWZ1YeCaV-Feco-eGXgW12UwU-9LbcBnxtXdw=s64","userId":"15756181896059802111"}},"outputId":"5b417be9-ffca-4464-9e4d-82abea158304"},"source":["from keras.models import load_model\n","\n","model = load_model('alexnet_cifar10_1000_2.h5')\n","model.summary()  # As a reminder."],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 32, 32, 96)        2688      \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 16, 16, 96)       0         \n"," )                                                               \n","                                                                 \n"," batch_normalization (BatchN  (None, 16, 16, 96)       384       \n"," ormalization)                                                   \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 16, 16, 256)       614656    \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 8, 8, 256)        0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 8, 8, 256)        1024      \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 8, 8, 384)         885120    \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 8, 8, 384)         1327488   \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 8, 8, 256)         884992    \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 4, 4, 256)        0         \n"," 2D)                                                             \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 4, 4, 256)        1024      \n"," hNormalization)                                                 \n","                                                                 \n"," flatten (Flatten)           (None, 4096)              0         \n","                                                                 \n"," dense (Dense)               (None, 1000)              4097000   \n","                                                                 \n"," dropout (Dropout)           (None, 1000)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1000)              1001000   \n","                                                                 \n"," dropout_1 (Dropout)         (None, 1000)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                10010     \n","                                                                 \n","=================================================================\n","Total params: 8,825,386\n","Trainable params: 8,824,170\n","Non-trainable params: 1,216\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"IkjhVvNxUPZs"},"source":["## cifar10データセットをロード"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KmQz45NVUONT","executionInfo":{"status":"ok","timestamp":1637035679180,"user_tz":-540,"elapsed":5438,"user":{"displayName":"吉岡拓郎","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivDrWZ1YeCaV-Feco-eGXgW12UwU-9LbcBnxtXdw=s64","userId":"15756181896059802111"}},"outputId":"4c032e43-3c6d-4f6d-e402-ce036e518d9c"},"source":["from keras.datasets import cifar10\n","\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 2s 0us/step\n","170508288/170498071 [==============================] - 2s 0us/step\n"]}]},{"cell_type":"markdown","metadata":{"id":"KIunViQDUbA7"},"source":["- なんか色々インポートしてます"]},{"cell_type":"code","metadata":{"id":"h4ngnkqEUbUn","executionInfo":{"status":"ok","timestamp":1637035679184,"user_tz":-540,"elapsed":14,"user":{"displayName":"吉岡拓郎","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivDrWZ1YeCaV-Feco-eGXgW12UwU-9LbcBnxtXdw=s64","userId":"15756181896059802111"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from keras.preprocessing import image\n","import numpy as np\n","import csv\n","from keras import models"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L8PwIzCtUj8N"},"source":["- x_testに入っている1万件の画像を使いたいと思います．"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FJuhZ2r8Ukau","executionInfo":{"status":"ok","timestamp":1637035683113,"user_tz":-540,"elapsed":207,"user":{"displayName":"吉岡拓郎","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivDrWZ1YeCaV-Feco-eGXgW12UwU-9LbcBnxtXdw=s64","userId":"15756181896059802111"}},"outputId":"33da379c-2cbc-4692-84c0-8d060e2068c3"},"source":["x_test.shape"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 32, 32, 3)"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"O7caFDufUxMY"},"source":["## 予測ベクトルを取得，csvファイルに保存\n","\n","- 現在，予測ベクトルはfor文の中ですべて取得できている．\n","- csvファイルにベクトルを保存することができた．"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"id":"-bBaSmoRUx9h","executionInfo":{"status":"ok","timestamp":1637038439110,"user_tz":-540,"elapsed":2742346,"user":{"displayName":"吉岡拓郎","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivDrWZ1YeCaV-Feco-eGXgW12UwU-9LbcBnxtXdw=s64","userId":"15756181896059802111"}},"outputId":"4f190699-995a-441d-bc43-f6ba345bd931"},"source":["for i in range(0,10000):\n","        x = x_test[i]\n","\n","        #ターゲット(画像)へのローカルパス\n","        img_path = x_test[i]\n","\n","        #画像を読み込む　:imgはサイズが224*224のPIL画像(Pythonで画像を処理するためのライブラリ)\n","        #img = image.load_img(img_path, target_size=(32,32))\n","\n","        #xは形状が(224,224，3)のfloat32型のNumPy配列\n","        #x = image.img_to_array(img)\n","\n","        #この配列がサイズが(1,224,224,3)のバッチに変換するために次元を追加\n","        x = np.expand_dims(x, axis=0)\n","\n","        #予測ベクトルを人が読める形にデコード\n","        preds = model.predict(x)\n","\n","        \n","\n","        # Extracts the outputs of the top 8 layers:\n","        layer_outputs = [layer.output for layer in model.layers[:15]]\n","        # Creates a model that will return these outputs, given the model input:\n","        activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n","        activations = activation_model.predict(x)\n","\n","        fifteen_layer = activations[14]\n","        # Creates a model that will return these outputs, given the model input:\n","        activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n","\n","        with open('/content/test_vector0.csv', 'a') as f:\n","          writer = csv.writer(f, lineterminator='\\n')\n","          writer.writerows(fifteen_layer)\n","\n","\"\"\"\n","        f = open('test_vector.csv' , 'w')\n","        writer = csv.writer(f, lineterminator='\\n')\n","        writer.writerow(fifteen_layer)\n","        f.close()\n","\"\"\""],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb998583830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb998583170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\n        f = open('test_vector.csv' , 'w')\\n        writer = csv.writer(f, lineterminator='\\n')\\n        writer.writerow(fifteen_layer)\\n        f.close()\\n\""]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"PE_Ktxap-vPK"},"source":["## 保存した大量のベクトルデータをzipファイルにしてダウンロード"]},{"cell_type":"code","metadata":{"id":"i4PCsnU_HQov"},"source":["# ダウンロードしたいフォルダを zip 圧縮する\n","!zip -r /content/download.zip /content/test_vector\n","\n","# 圧縮した zip ファイルをダウンロードする\n","from google.colab import files\n","files.download(\"/content/download.zip\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VxdAuMHs6eBL"},"source":[""],"execution_count":null,"outputs":[]}]}